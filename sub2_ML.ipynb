{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tested:\n",
    "- AdaBoost ok\n",
    "- RandomForest ok\n",
    "- KNeighbours ok\n",
    "- MLP no P/F\n",
    "- DecisionTree no P/F\n",
    "- SVC linear or gamma='scale' no, takes too long\n",
    "- Gaussian Process no, needs a lot of space\n",
    "- LinearSVC (similar to SVC, buit based on liblinear) no, takes too long\n",
    "- SGD ok\n",
    "- Naive Bayes ok\n",
    "- Quadratic Discriminant ok\n",
    "- Logistic Regression no P/F\n",
    "- Ridge no P/F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv('reddit_exploded.csv')\n",
    "test_data = pd.read_csv('reddit_exploded_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target variable\n",
    "X_train = train_data.drop(columns=['LINK_SENTIMENT', 'PROPERTIES', 'TIMESTAMP'])\n",
    "y_train = train_data['LINK_SENTIMENT']\n",
    "\n",
    "X_test = test_data.drop(columns=['LINK_SENTIMENT', 'PROPERTIES', 'TIMESTAMP'])\n",
    "y_test = test_data['LINK_SENTIMENT']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=69)\n",
    "\n",
    "# List of text feature columns\n",
    "text_features = ['Num_Characters', 'Num_Characters_No_Whitespace', 'Fraction_Alphabetical',\n",
    "    'Fraction_Digits', 'Fraction_Uppercase', 'Fraction_Whitespace',\n",
    "    'Fraction_Special_Characters', 'Num_Words', 'Num_Unique_Words',\n",
    "    'Num_Long_Words', 'Avg_Word_Length', 'Num_Unique_Stopwords',\n",
    "    'Fraction_Stopwords', 'Num_Sentences', 'Num_Long_Sentences',\n",
    "    'Avg_Characters_Per_Sentence', 'Avg_Words_Per_Sentence',\n",
    "    'Automated_Readability_Index', 'Positive_Sentiment_VADER',\n",
    "    'Negative_Sentiment_VADER', 'Compound_Sentiment_VADER',\n",
    "    'LIWC_Funct', 'LIWC_Pronoun', 'LIWC_Ppron', 'LIWC_I', 'LIWC_We',\n",
    "    'LIWC_You', 'LIWC_SheHe', 'LIWC_They', 'LIWC_Ipron', 'LIWC_Article',\n",
    "    'LIWC_Verbs', 'LIWC_AuxVb', 'LIWC_Past', 'LIWC_Present', 'LIWC_Future',\n",
    "    'LIWC_Adverbs', 'LIWC_Prep', 'LIWC_Conj', 'LIWC_Negate', 'LIWC_Quant',\n",
    "    'LIWC_Numbers', 'LIWC_Swear', 'LIWC_Social', 'LIWC_Family', 'LIWC_Friends',\n",
    "    'LIWC_Humans', 'LIWC_Affect', 'LIWC_Posemo', 'LIWC_Negemo', 'LIWC_Anx',\n",
    "    'LIWC_Anger', 'LIWC_Sad', 'LIWC_CogMech', 'LIWC_Insight', 'LIWC_Cause',\n",
    "    'LIWC_Discrep', 'LIWC_Tentat', 'LIWC_Certain', 'LIWC_Inhib', 'LIWC_Incl',\n",
    "    'LIWC_Excl', 'LIWC_Percept', 'LIWC_See', 'LIWC_Hear', 'LIWC_Feel',\n",
    "    'LIWC_Bio', 'LIWC_Body', 'LIWC_Health', 'LIWC_Sexual', 'LIWC_Ingest',\n",
    "    'LIWC_Relativ', 'LIWC_Motion', 'LIWC_Space', 'LIWC_Time', 'LIWC_Work',\n",
    "    'LIWC_Achiev', 'LIWC_Leisure', 'LIWC_Home', 'LIWC_Money', 'LIWC_Relig',\n",
    "    'LIWC_Death', 'LIWC_Assent', 'LIWC_Dissent', 'LIWC_Nonflu', 'LIWC_Filler']\n",
    "\n",
    "# List of numerical feature columns\n",
    "numeric_features = ['year', 'month', 'day', 'weekday', 'hour']\n",
    "\n",
    "# Select the text and numerical features\n",
    "X_train_text = X_train[text_features]\n",
    "X_test_text = X_test[text_features]\n",
    "\n",
    "X_train_numeric = X_train[numeric_features]\n",
    "X_test_numeric = X_test[numeric_features]\n",
    "\n",
    "# Combine the features\n",
    "X_train_combined = pd.concat([X_train_text, X_train_numeric], axis=1)\n",
    "X_test_combined = pd.concat([X_test_text, X_test_numeric], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      0.01      0.01       382\n",
      "           1       0.92      1.00      0.96      4617\n",
      "\n",
      "    accuracy                           0.92      4999\n",
      "   macro avg       0.71      0.50      0.49      4999\n",
      "weighted avg       0.89      0.92      0.89      4999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a machine learning model\n",
    "clf = AdaBoostClassifier(random_state=42)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the model\n",
    "report_AB = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-1': {'precision': 0.5,\n",
       "  'recall': 0.005235602094240838,\n",
       "  'f1-score': 0.010362694300518137,\n",
       "  'support': 382},\n",
       " '1': {'precision': 0.923923923923924,\n",
       "  'recall': 0.9995668182802686,\n",
       "  'f1-score': 0.9602580108198087,\n",
       "  'support': 4617},\n",
       " 'accuracy': 0.9235847169433887,\n",
       " 'macro avg': {'precision': 0.7119619619619619,\n",
       "  'recall': 0.5024012101872547,\n",
       "  'f1-score': 0.4853103525601634,\n",
       "  'support': 4999},\n",
       " 'weighted avg': {'precision': 0.8915296572828079,\n",
       "  'recall': 0.9235847169433887,\n",
       "  'f1-score': 0.8876714913338377,\n",
       "  'support': 4999}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      0.08      0.14       382\n",
      "           1       0.93      0.99      0.96      4617\n",
      "\n",
      "    accuracy                           0.92      4999\n",
      "   macro avg       0.66      0.54      0.55      4999\n",
      "weighted avg       0.89      0.92      0.90      4999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a machine learning model\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the model\n",
    "report_RF = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.38      0.04      0.07       382\n",
      "           1       0.93      0.99      0.96      4617\n",
      "\n",
      "    accuracy                           0.92      4999\n",
      "   macro avg       0.66      0.52      0.52      4999\n",
      "weighted avg       0.88      0.92      0.89      4999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a machine learning model\n",
    "clf = KNeighborsClassifier(10, n_jobs=6)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the model\n",
    "report_KN = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a machine learning model\n",
    "# clf = MLPClassifier(alpha=1, max_iter=1500, random_state=42) # Precision and F-score aren't properly set\n",
    "# clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# # Evaluate the model\n",
    "# report_MLP = classification_report(y_test, y_pred, output_dict=True)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a machine learning model\n",
    "# clf = DecisionTreeClassifier(max_depth=5, random_state=42) precision and f-score aren't properly set\n",
    "# clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# # Evaluate the model\n",
    "# report_DT = classification_report(y_test, y_pred, output_dict=True)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a machine learning model\n",
    "# clf = SVC(kernel=\"linear\", C=0.025, random_state=42) # Interrupted at 35 minutes - SVC linear just takes too long for big datasets\n",
    "# clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# # Evaluate the model\n",
    "# report_SVClin = classification_report(y_test, y_pred)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a machine learning model\n",
    "# clf = SVC(gamma='scale', random_state=42) # Interrupted at 30 minutes - seems to have the same scaling problems as SVC linear\n",
    "# clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# # Evaluate the model\n",
    "# report_SVC = classification_report(y_test, y_pred)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a machine learning model\n",
    "# clf = LinearSVC(max_iter = 1000, random_state=42) # linear SVC takes too long on \"large\" datasets\n",
    "# clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# # Evaluate the model\n",
    "# report_linSVC = classification_report(y_test, y_pred, output_dict=True)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.09      0.59      0.16       382\n",
      "           1       0.94      0.52      0.67      4617\n",
      "\n",
      "    accuracy                           0.53      4999\n",
      "   macro avg       0.52      0.56      0.42      4999\n",
      "weighted avg       0.87      0.53      0.63      4999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a machine learning model\n",
    "clf = SGDClassifier(random_state=42)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the model\n",
    "report_SGD = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a machine learning model; GPC seems to take very long\n",
    "# clf = GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42) # ended with Error: Unable to allocate 591. GiB for an array with shape (281562, 281562) and data type float64\n",
    "# clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# # Evaluate the model\n",
    "# report_GP = classification_report(y_test, y_pred)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a machine learning model\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the model\n",
    "report_NB = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cravi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.09      0.86      0.17       382\n",
      "           1       0.96      0.30      0.45      4617\n",
      "\n",
      "    accuracy                           0.34      4999\n",
      "   macro avg       0.53      0.58      0.31      4999\n",
      "weighted avg       0.90      0.34      0.43      4999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a machine learning model\n",
    "clf = QuadraticDiscriminantAnalysis()\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the model\n",
    "report_QD = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a machine learning model\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# clf = LogisticRegression(random_state=42) # Precision and F-score aren't properly set\n",
    "# clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# # Evaluate the model\n",
    "# report_LogR = classification_report(y_test, y_pred, output_dict=True)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train a machine learning model\n",
    "# from sklearn.linear_model import RidgeClassifier # Precision and F-score aren't properly set\n",
    "\n",
    "\n",
    "# clf = RidgeClassifier(random_state=42)\n",
    "# clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = clf.predict(X_test_combined)\n",
    "\n",
    "# # Evaluate the model\n",
    "# report_R = classification_report(y_test, y_pred, output_dict=True)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
